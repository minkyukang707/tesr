{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle \n",
    "from os import path\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mixed - dtype 정책설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU (UUID: GPU-ee7f401a-8dfd-8593-41bd-c2179a0cf87a)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070 Laptop GPU, compute capability 8.6\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\mixed_precision\\loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Sub_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>10101</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "      <td>1430</td>\n",
       "      <td>982</td>\n",
       "      <td>982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-Ackflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2179</td>\n",
       "      <td>554</td>\n",
       "      <td>6</td>\n",
       "      <td>5310</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>2261.327486</td>\n",
       "      <td>4254</td>\n",
       "      <td>1056</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>DoS</td>\n",
       "      <td>DoS-Synflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52727</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Scan</td>\n",
       "      <td>Scan Port OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52964</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-Hostbruteforceg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36763</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>886</td>\n",
       "      <td>420</td>\n",
       "      <td>452</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-Hostbruteforceg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Src_Port  Dst_Port  Protocol  Flow_Duration  Tot_Fwd_Pkts  Tot_Bwd_Pkts  \\\n",
       "0     10000     10101        17             75             1             1   \n",
       "1      2179       554         6           5310             1             2   \n",
       "2     52727      9020         6            141             0             3   \n",
       "3     52964      9020         6            151             0             2   \n",
       "4     36763      1900        17            153             2             1   \n",
       "\n",
       "   TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  ...  \\\n",
       "0              982             1430              982              982  ...   \n",
       "1                0                0                0                0  ...   \n",
       "2                0             2806                0                0  ...   \n",
       "3                0             2776                0                0  ...   \n",
       "4              886              420              452              434  ...   \n",
       "\n",
       "   Active_Std  Active_Max  Active_Min  Idle_Mean     Idle_Std  Idle_Max  \\\n",
       "0         0.0           0           0       75.0     0.000000        75   \n",
       "1         0.0           0           0     2655.0  2261.327486      4254   \n",
       "2         0.0           0           0       70.5     0.707107        71   \n",
       "3         0.0           0           0      151.0     0.000000       151   \n",
       "4         0.0           0           0       76.5     0.707107        77   \n",
       "\n",
       "   Idle_Min    Label    Cat                Sub_Cat  \n",
       "0        75  Anomaly  Mirai      Mirai-Ackflooding  \n",
       "1      1056  Anomaly    DoS        DoS-Synflooding  \n",
       "2        70  Anomaly   Scan           Scan Port OS  \n",
       "3       151  Anomaly  Mirai  Mirai-Hostbruteforceg  \n",
       "4        76  Anomaly  Mirai  Mirai-Hostbruteforceg  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset_original.csv')\n",
    "\n",
    "data.head()\n",
    "new_data = data.drop(columns=['Flow_ID', 'Src_IP', 'Dst_IP', 'Timestamp'])\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using minmax scaler for normalizing data\n",
    "minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "def normalization(df,col):\n",
    "  for i in col:\n",
    "    arr = df[i]\n",
    "    arr = np.array(arr)\n",
    "    df[i] = minmax_scale.fit_transform(arr.reshape(len(arr),1))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cat_data = new_data.drop(columns= ['Label', 'Cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = sub_cat_data.select_dtypes(include='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cat_data = sub_cat_data.replace([np.inf, -np.inf], np.nan)\n",
    "sub_cat_data = sub_cat_data.dropna()\n",
    "sub_cat_data = normalization(sub_cat_data, num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625415, 80)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_cat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cat_data.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625415, 80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_cat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_Seg_Size_Min</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "      <th>Sub_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.152672</td>\n",
       "      <td>0.154518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.670765</td>\n",
       "      <td>0.670765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>Mirai-Ackflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033267</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.053099</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>DoS-Synflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804992</td>\n",
       "      <td>0.137982</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>Scan Port OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808611</td>\n",
       "      <td>0.137982</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>Mirai-Hostbruteforceg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.561267</td>\n",
       "      <td>0.029065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.308743</td>\n",
       "      <td>0.296448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>Mirai-Hostbruteforceg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625778</th>\n",
       "      <td>0.856672</td>\n",
       "      <td>0.123036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>Mirai-UDP Flooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625779</th>\n",
       "      <td>0.069771</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>DoS-Synflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625780</th>\n",
       "      <td>0.805176</td>\n",
       "      <td>0.137982</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>Scan Port OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625781</th>\n",
       "      <td>0.137710</td>\n",
       "      <td>0.761561</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625782</th>\n",
       "      <td>0.152672</td>\n",
       "      <td>0.154518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026036</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>Mirai-UDP Flooding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625415 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Src_Port  Dst_Port  Protocol  Flow_Duration  Tot_Fwd_Pkts  \\\n",
       "0       0.152672  0.154518  1.000000       0.000740      0.005376   \n",
       "1       0.033267  0.008475  0.352941       0.053099      0.005376   \n",
       "2       0.804992  0.137982  0.352941       0.001400      0.000000   \n",
       "3       0.808611  0.137982  0.352941       0.001500      0.000000   \n",
       "4       0.561267  0.029065  1.000000       0.001520      0.010753   \n",
       "...          ...       ...       ...            ...           ...   \n",
       "625778  0.856672  0.123036  1.000000       0.002760      0.005376   \n",
       "625779  0.069771  0.008475  0.352941       0.016573      0.000000   \n",
       "625780  0.805176  0.137982  0.352941       0.000760      0.005376   \n",
       "625781  0.137710  0.761561  0.352941       0.002390      0.010753   \n",
       "625782  0.152672  0.154518  1.000000       0.001970      0.010753   \n",
       "\n",
       "        Tot_Bwd_Pkts  TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  \\\n",
       "0           0.000000         0.008940         0.001849         0.670765   \n",
       "1           0.001789         0.000000         0.000000         0.000000   \n",
       "2           0.003578         0.000000         0.003629         0.000000   \n",
       "3           0.001789         0.000000         0.003590         0.000000   \n",
       "4           0.000000         0.008066         0.000543         0.308743   \n",
       "...              ...              ...              ...              ...   \n",
       "625778      0.000000         0.000164         0.000023         0.012295   \n",
       "625779      0.001789         0.000000         0.000000         0.000000   \n",
       "625780      0.000000         0.000000         0.000000         0.000000   \n",
       "625781      0.000000         0.025272         0.001795         0.948087   \n",
       "625782      0.000000         0.026036         0.001849         0.976776   \n",
       "\n",
       "        Fwd_Pkt_Len_Min  ...  Fwd_Seg_Size_Min  Active_Mean  Active_Std  \\\n",
       "0              0.670765  ...               0.0          0.0         0.0   \n",
       "1              0.000000  ...               0.0          0.0         0.0   \n",
       "2              0.000000  ...               0.0          0.0         0.0   \n",
       "3              0.000000  ...               0.0          0.0         0.0   \n",
       "4              0.296448  ...               0.0          0.0         0.0   \n",
       "...                 ...  ...               ...          ...         ...   \n",
       "625778         0.012295  ...               0.0          0.0         0.0   \n",
       "625779         0.000000  ...               0.0          0.0         0.0   \n",
       "625780         0.000000  ...               0.0          0.0         0.0   \n",
       "625781         0.948087  ...               0.0          0.0         0.0   \n",
       "625782         0.976776  ...               0.0          0.0         0.0   \n",
       "\n",
       "        Active_Max  Active_Min  Idle_Mean  Idle_Std  Idle_Max  Idle_Min  \\\n",
       "0              0.0         0.0   0.000750  0.000000  0.000750  0.000750   \n",
       "1              0.0         0.0   0.026557  0.033715  0.042551  0.010563   \n",
       "2              0.0         0.0   0.000705  0.000011  0.000710  0.000700   \n",
       "3              0.0         0.0   0.001510  0.000000  0.001510  0.001510   \n",
       "4              0.0         0.0   0.000765  0.000011  0.000770  0.000760   \n",
       "...            ...         ...        ...       ...       ...       ...   \n",
       "625778         0.0         0.0   0.002771  0.000000  0.002771  0.002771   \n",
       "625779         0.0         0.0   0.016584  0.000000  0.016584  0.016584   \n",
       "625780         0.0         0.0   0.000770  0.000000  0.000770  0.000770   \n",
       "625781         0.0         0.0   0.001200  0.000105  0.001250  0.001150   \n",
       "625782         0.0         0.0   0.000990  0.000485  0.001220  0.000760   \n",
       "\n",
       "                      Sub_Cat  \n",
       "0           Mirai-Ackflooding  \n",
       "1             DoS-Synflooding  \n",
       "2                Scan Port OS  \n",
       "3       Mirai-Hostbruteforceg  \n",
       "4       Mirai-Hostbruteforceg  \n",
       "...                       ...  \n",
       "625778     Mirai-UDP Flooding  \n",
       "625779        DoS-Synflooding  \n",
       "625780           Scan Port OS  \n",
       "625781                 Normal  \n",
       "625782     Mirai-UDP Flooding  \n",
       "\n",
       "[625415 rows x 80 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_cat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DoS-Synflooding  MITM ARP Spoofing  Mirai-Ackflooding  \\\n",
      "0                     0                  0                  1   \n",
      "1                     1                  0                  0   \n",
      "2                     0                  0                  0   \n",
      "3                     0                  0                  0   \n",
      "4                     0                  0                  0   \n",
      "...                 ...                ...                ...   \n",
      "625778                0                  0                  0   \n",
      "625779                1                  0                  0   \n",
      "625780                0                  0                  0   \n",
      "625781                0                  0                  0   \n",
      "625782                0                  0                  0   \n",
      "\n",
      "        Mirai-HTTP Flooding  Mirai-Hostbruteforceg  Mirai-UDP Flooding  \\\n",
      "0                         0                      0                   0   \n",
      "1                         0                      0                   0   \n",
      "2                         0                      0                   0   \n",
      "3                         0                      1                   0   \n",
      "4                         0                      1                   0   \n",
      "...                     ...                    ...                 ...   \n",
      "625778                    0                      0                   1   \n",
      "625779                    0                      0                   0   \n",
      "625780                    0                      0                   0   \n",
      "625781                    0                      0                   0   \n",
      "625782                    0                      0                   1   \n",
      "\n",
      "        Normal  Scan Hostport  Scan Port OS  \n",
      "0            0              0             0  \n",
      "1            0              0             0  \n",
      "2            0              0             1  \n",
      "3            0              0             0  \n",
      "4            0              0             0  \n",
      "...        ...            ...           ...  \n",
      "625778       0              0             0  \n",
      "625779       0              0             0  \n",
      "625780       0              0             1  \n",
      "625781       1              0             0  \n",
      "625782       0              0             0  \n",
      "\n",
      "[625415 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "ohe=pd.get_dummies(sub_cat_data['Sub_Cat'])\n",
    "print(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sub_cat_data.iloc[:, :-1]\n",
    "y = ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subset= X.iloc[600000:610000,:]\n",
    "y_subset=y.iloc[600000:610000,:]\n",
    "\n",
    "X_subset.to_csv('x_subset.csv', header=False)\n",
    "y_subset.to_csv('y_subset.csv',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=79,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(128,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              81920     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               393728    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 1,428,233\n",
      "Trainable params: 1,428,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mixed - model 구축 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024,input_dim=79,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(768,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(512,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(256,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(128,activation='relu'))  \n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(9, activation='softmax', dtype='float32', name = 'predictions'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(x)\n",
    "    loss = loss_object(y, predictions)\n",
    "    scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "  scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "  gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x):\n",
    "  return model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                 .shuffle(10000).batch(256))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 TFLite 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmp3nfg9lt8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmp3nfg9lt8\\assets\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "c:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Cast' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Cast' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: BiasAdd, Cast, MatMul, Relu\nDetails:\n\ttf.BiasAdd(tensor<?x1024xf16>, tensor<1024xf16>) -> (tensor<?x1024xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x128xf16>, tensor<128xf16>) -> (tensor<?x128xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x256xf16>, tensor<256xf16>) -> (tensor<?x256xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x512xf16>, tensor<512xf16>) -> (tensor<?x512xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x768xf16>, tensor<768xf16>) -> (tensor<?x768xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.Cast(tensor<?x128xf16>) -> (tensor<?x128xf32>) : {Truncate = false, device = \"\"}\n\ttf.Cast(tensor<?x79xf32>) -> (tensor<?x79xf16>) : {Truncate = false, device = \"\"}\n\ttf.MatMul(tensor<?x1024xf16>, tensor<768x1024xf16>) -> (tensor<?x768xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x256xf16>, tensor<128x256xf16>) -> (tensor<?x128xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x512xf16>, tensor<256x512xf16>) -> (tensor<?x256xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x768xf16>, tensor<512x768xf16>) -> (tensor<?x512xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x79xf16>, tensor<1024x79xf16>) -> (tensor<?x1024xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.Relu(tensor<?x1024xf16>) -> (tensor<?x1024xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x128xf16>) -> (tensor<?x128xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x256xf16>) -> (tensor<?x256xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x512xf16>) -> (tensor<?x512xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x768xf16>) -> (tensor<?x768xf16>) : {device = \"\"}\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\nls0629\\DNN_original_transfer.ipynb 셀 33\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000069?line=0'>1</a>\u001b[0m converter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mTFLiteConverter\u001b[39m.\u001b[39mfrom_keras_model(model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000069?line=1'>2</a>\u001b[0m tflite_model \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mconvert()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000069?line=3'>4</a>\u001b[0m tflite_models_dir \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(\u001b[39m\"\u001b[39m\u001b[39mmodel0726/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# tflite 모델 저장 경로 입력 \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000069?line=4'>5</a>\u001b[0m tflite_models_dir\u001b[39m.\u001b[39mmkdir(exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:729\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(convert_func)\n\u001b[0;32m    727\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    728\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 729\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_and_export_metrics(convert_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:715\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m    714\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m--> 715\u001b[0m result \u001b[39m=\u001b[39m convert_func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    716\u001b[0m elapsed_time_ms \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m start_time) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m    717\u001b[0m \u001b[39mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1128\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1122\u001b[0m graph_def, input_tensors, output_tensors, frozen_func \u001b[39m=\u001b[39m (\n\u001b[0;32m   1123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_freeze_keras_model())\n\u001b[0;32m   1125\u001b[0m graph_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimize_tf_model(graph_def, input_tensors,\n\u001b[0;32m   1126\u001b[0m                                     output_tensors, frozen_func)\n\u001b[1;32m-> 1128\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TFLiteKerasModelConverterV2,\n\u001b[0;32m   1129\u001b[0m              \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mconvert(graph_def, input_tensors, output_tensors)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:897\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m    892\u001b[0m   logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mUsing new converter: If you encounter a problem \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mplease file a bug. You can opt-out \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    894\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mby setting experimental_new_converter=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    896\u001b[0m \u001b[39m# Converts model.\u001b[39;00m\n\u001b[1;32m--> 897\u001b[0m result \u001b[39m=\u001b[39m _toco_convert_impl(\n\u001b[0;32m    898\u001b[0m     input_data\u001b[39m=\u001b[39mgraph_def,\n\u001b[0;32m    899\u001b[0m     input_tensors\u001b[39m=\u001b[39minput_tensors,\n\u001b[0;32m    900\u001b[0m     output_tensors\u001b[39m=\u001b[39moutput_tensors,\n\u001b[0;32m    901\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconverter_kwargs)\n\u001b[0;32m    903\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimize_tflite_model(\n\u001b[0;32m    904\u001b[0m     result, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_quant_mode, quant_io\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_new_quantizer)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     report_error_message(\u001b[39mstr\u001b[39m(converter_error))\n\u001b[1;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m converter_error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m  \u001b[39m# Re-throws the exception.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    217\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:208\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    207\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    209\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[0;32m    210\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:795\u001b[0m, in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m model_flags, toco_flags, debug_info \u001b[39m=\u001b[39m build_toco_convert_protos(\n\u001b[0;32m    793\u001b[0m     input_tensors, output_tensors, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    794\u001b[0m debug_info_str \u001b[39m=\u001b[39m debug_info\u001b[39m.\u001b[39mSerializeToString() \u001b[39mif\u001b[39;00m debug_info \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m data \u001b[39m=\u001b[39m toco_convert_protos(\n\u001b[0;32m    796\u001b[0m     model_flags\u001b[39m.\u001b[39;49mSerializeToString(),\n\u001b[0;32m    797\u001b[0m     toco_flags\u001b[39m.\u001b[39;49mSerializeToString(),\n\u001b[0;32m    798\u001b[0m     input_data\u001b[39m.\u001b[39;49mSerializeToString(),\n\u001b[0;32m    799\u001b[0m     debug_info_str\u001b[39m=\u001b[39;49mdebug_info_str,\n\u001b[0;32m    800\u001b[0m     enable_mlir_converter\u001b[39m=\u001b[39;49menable_mlir_converter)\n\u001b[0;32m    801\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:313\u001b[0m, in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[39mfor\u001b[39;00m error_data \u001b[39min\u001b[39;00m _metrics_wrapper\u001b[39m.\u001b[39mretrieve_collected_errors():\n\u001b[0;32m    312\u001b[0m       converter_error\u001b[39m.\u001b[39mappend_error(error_data)\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mraise\u001b[39;00m converter_error\n\u001b[0;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m _run_toco_binary(model_flags_str, toco_flags_str, input_data_str,\n\u001b[0;32m    316\u001b[0m                         debug_info_str)\n",
      "\u001b[1;31mConverterError\u001b[0m: c:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Cast' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.MatMul' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.BiasAdd' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Relu' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: error: 'tf.Cast' op is neither a custom op nor a flex op\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\base_layer.py:1037:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:194:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1213:0: note: called from\nc:\\Users\\user\\anaconda3\\envs\\mixed\\lib\\site-packages\\keras\\engine\\sequential.py:369:0: note: Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: BiasAdd, Cast, MatMul, Relu\nDetails:\n\ttf.BiasAdd(tensor<?x1024xf16>, tensor<1024xf16>) -> (tensor<?x1024xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x128xf16>, tensor<128xf16>) -> (tensor<?x128xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x256xf16>, tensor<256xf16>) -> (tensor<?x256xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x512xf16>, tensor<512xf16>) -> (tensor<?x512xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.BiasAdd(tensor<?x768xf16>, tensor<768xf16>) -> (tensor<?x768xf16>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.Cast(tensor<?x128xf16>) -> (tensor<?x128xf32>) : {Truncate = false, device = \"\"}\n\ttf.Cast(tensor<?x79xf32>) -> (tensor<?x79xf16>) : {Truncate = false, device = \"\"}\n\ttf.MatMul(tensor<?x1024xf16>, tensor<768x1024xf16>) -> (tensor<?x768xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x256xf16>, tensor<128x256xf16>) -> (tensor<?x128xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x512xf16>, tensor<256x512xf16>) -> (tensor<?x256xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x768xf16>, tensor<512x768xf16>) -> (tensor<?x512xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.MatMul(tensor<?x79xf16>, tensor<1024x79xf16>) -> (tensor<?x1024xf16>) : {transpose_a = false, transpose_b = true}\n\ttf.Relu(tensor<?x1024xf16>) -> (tensor<?x1024xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x128xf16>) -> (tensor<?x128xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x256xf16>) -> (tensor<?x256xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x512xf16>) -> (tensor<?x512xf16>) : {device = \"\"}\n\ttf.Relu(tensor<?x768xf16>) -> (tensor<?x768xf16>) : {device = \"\"}\n\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"model0726/\") # tflite 모델 저장 경로 입력 \n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "tflite_model_file = tflite_models_dir/\"model_0726.tflite\" # 모델 이름 작성 \n",
    "tflite_model_file.write_bytes(tflite_model) # 모델 크기 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1711/1711 [00:24<00:00, 68.96it/s]\n",
      "100%|██████████| 733/733 [00:02<00:00, 343.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=0.7892550230026245, test accuracy=0.6926582455635071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1711/1711 [00:25<00:00, 67.70it/s]\n",
      "100%|██████████| 733/733 [00:02<00:00, 359.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.6633138656616211, test accuracy=0.6869766712188721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 210/1711 [00:03<00:22, 68.11it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  test_accuracy = tf.keras.metrics.CategoricalAccuracy(\n",
    "      name='test_accuracy')\n",
    "  for x, y in tqdm.tqdm(train_dataset):\n",
    "    loss = train_step(x, y)\n",
    "    epoch_loss_avg(loss)\n",
    "  for x, y in tqdm.tqdm(test_dataset):\n",
    "    predictions = test_step(x)\n",
    "    test_accuracy.update_state(y, predictions)\n",
    "  print('Epoch {}: loss={}, test accuracy={}'.format(epoch, epoch_loss_avg.result(), test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "checkpoint_filepath = 'multiclass_best_model2.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5082 - accuracy: 0.7414 - val_loss: 0.6191 - val_accuracy: 0.7049\n",
      "Epoch 2/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5235 - accuracy: 0.7348 - val_loss: 0.5496 - val_accuracy: 0.7284\n",
      "Epoch 3/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5161 - accuracy: 0.7370 - val_loss: 0.4859 - val_accuracy: 0.7545\n",
      "Epoch 4/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5132 - accuracy: 0.7388 - val_loss: 0.5459 - val_accuracy: 0.7283\n",
      "Epoch 5/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5022 - accuracy: 0.7432 - val_loss: 0.5804 - val_accuracy: 0.7238\n",
      "Epoch 6/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5127 - accuracy: 0.7378 - val_loss: 0.5499 - val_accuracy: 0.7322\n",
      "Epoch 7/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4958 - accuracy: 0.7445 - val_loss: 0.4796 - val_accuracy: 0.7586\n",
      "Epoch 8/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5049 - accuracy: 0.7422 - val_loss: 0.5223 - val_accuracy: 0.7429\n",
      "Epoch 9/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5074 - accuracy: 0.7420 - val_loss: 0.5994 - val_accuracy: 0.7099\n",
      "Epoch 10/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5218 - accuracy: 0.7362 - val_loss: 0.5036 - val_accuracy: 0.7476\n",
      "Epoch 11/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5155 - accuracy: 0.7383 - val_loss: 0.5260 - val_accuracy: 0.7311\n",
      "Epoch 12/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5181 - accuracy: 0.7376 - val_loss: 0.5449 - val_accuracy: 0.7279\n",
      "Epoch 13/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5097 - accuracy: 0.7399 - val_loss: 0.5557 - val_accuracy: 0.7234\n",
      "Epoch 14/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5138 - accuracy: 0.7387 - val_loss: 0.5292 - val_accuracy: 0.7417\n",
      "Epoch 15/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5180 - accuracy: 0.7372 - val_loss: 0.5242 - val_accuracy: 0.7414\n",
      "Epoch 16/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5048 - accuracy: 0.7417 - val_loss: 0.5367 - val_accuracy: 0.7294\n",
      "Epoch 17/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5147 - accuracy: 0.7394 - val_loss: 0.5732 - val_accuracy: 0.7134\n",
      "Epoch 18/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5157 - accuracy: 0.7379 - val_loss: 0.5223 - val_accuracy: 0.7440\n",
      "Epoch 19/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5096 - accuracy: 0.7410 - val_loss: 0.6130 - val_accuracy: 0.7131\n",
      "Epoch 20/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4972 - accuracy: 0.7447 - val_loss: 0.5350 - val_accuracy: 0.7285\n",
      "Epoch 21/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5035 - accuracy: 0.7417 - val_loss: 0.5357 - val_accuracy: 0.7331\n",
      "Epoch 22/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5036 - accuracy: 0.7424 - val_loss: 0.5477 - val_accuracy: 0.7264\n",
      "Epoch 23/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5075 - accuracy: 0.7425 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
      "Epoch 24/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5124 - accuracy: 0.7382 - val_loss: 0.5206 - val_accuracy: 0.7395\n",
      "Epoch 25/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4933 - accuracy: 0.7470 - val_loss: 0.5031 - val_accuracy: 0.7456\n",
      "Epoch 26/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4989 - accuracy: 0.7441 - val_loss: 0.5606 - val_accuracy: 0.7222\n",
      "Epoch 27/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5009 - accuracy: 0.7432 - val_loss: 0.4804 - val_accuracy: 0.7590\n",
      "Epoch 28/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5037 - accuracy: 0.7432 - val_loss: 0.5568 - val_accuracy: 0.7179\n",
      "Epoch 29/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4975 - accuracy: 0.7452 - val_loss: 0.5846 - val_accuracy: 0.7139\n",
      "Epoch 30/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4961 - accuracy: 0.7454 - val_loss: 0.4835 - val_accuracy: 0.7579\n",
      "Epoch 31/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4972 - accuracy: 0.7452 - val_loss: 0.4842 - val_accuracy: 0.7589\n",
      "Epoch 32/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4957 - accuracy: 0.7457 - val_loss: 0.5125 - val_accuracy: 0.7399\n",
      "Epoch 33/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.4993 - accuracy: 0.7448 - val_loss: 0.4966 - val_accuracy: 0.7477\n",
      "Epoch 34/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.5095 - accuracy: 0.7411 - val_loss: 0.4947 - val_accuracy: 0.7557\n",
      "Epoch 35/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4983 - accuracy: 0.7447 - val_loss: 0.5801 - val_accuracy: 0.7304\n",
      "Epoch 36/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.5079 - accuracy: 0.7419 - val_loss: 0.4856 - val_accuracy: 0.7556\n",
      "Epoch 37/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5154 - accuracy: 0.7375 - val_loss: 0.5552 - val_accuracy: 0.7330\n",
      "Epoch 38/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5098 - accuracy: 0.7392 - val_loss: 0.5253 - val_accuracy: 0.7385\n",
      "Epoch 39/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5129 - accuracy: 0.7386 - val_loss: 0.5010 - val_accuracy: 0.7527\n",
      "Epoch 40/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5012 - accuracy: 0.7438 - val_loss: 0.4949 - val_accuracy: 0.7514\n",
      "Epoch 41/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4912 - accuracy: 0.7471 - val_loss: 0.4901 - val_accuracy: 0.7518\n",
      "Epoch 42/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5031 - accuracy: 0.7420 - val_loss: 0.5406 - val_accuracy: 0.7287\n",
      "Epoch 43/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4943 - accuracy: 0.7472 - val_loss: 0.6093 - val_accuracy: 0.6988\n",
      "Epoch 44/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4937 - accuracy: 0.7455 - val_loss: 0.4940 - val_accuracy: 0.7489\n",
      "Epoch 45/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4936 - accuracy: 0.7460 - val_loss: 0.5016 - val_accuracy: 0.7467\n",
      "Epoch 46/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4899 - accuracy: 0.7470 - val_loss: 0.5695 - val_accuracy: 0.7294\n",
      "Epoch 47/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4993 - accuracy: 0.7435 - val_loss: 0.4902 - val_accuracy: 0.7527\n",
      "Epoch 48/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4995 - accuracy: 0.7437 - val_loss: 0.4953 - val_accuracy: 0.7518\n",
      "Epoch 49/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4984 - accuracy: 0.7441 - val_loss: 0.5361 - val_accuracy: 0.7337\n",
      "Epoch 50/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.4998 - accuracy: 0.7424 - val_loss: 0.5136 - val_accuracy: 0.7352\n",
      "Epoch 51/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5001 - accuracy: 0.7437 - val_loss: 0.5480 - val_accuracy: 0.7310\n",
      "Epoch 52/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.5042 - accuracy: 0.7432 - val_loss: 0.4922 - val_accuracy: 0.7539\n",
      "Epoch 53/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5344 - accuracy: 0.7404 - val_loss: 0.5221 - val_accuracy: 0.7354\n",
      "Epoch 54/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5137 - accuracy: 0.7407 - val_loss: 0.4928 - val_accuracy: 0.7475\n",
      "Epoch 55/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5077 - accuracy: 0.7413 - val_loss: 0.5340 - val_accuracy: 0.7365\n",
      "Epoch 56/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5016 - accuracy: 0.7439 - val_loss: 0.5717 - val_accuracy: 0.7181\n",
      "Epoch 57/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5070 - accuracy: 0.7412 - val_loss: 0.5956 - val_accuracy: 0.7220\n",
      "Epoch 58/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.4977 - accuracy: 0.7439 - val_loss: 0.4883 - val_accuracy: 0.7553\n",
      "Epoch 59/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.4940 - accuracy: 0.7461 - val_loss: 0.5014 - val_accuracy: 0.7505\n",
      "Epoch 60/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.5105 - accuracy: 0.7395 - val_loss: 0.5441 - val_accuracy: 0.7221\n",
      "Epoch 61/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5047 - accuracy: 0.7410 - val_loss: 0.5456 - val_accuracy: 0.7356\n",
      "Epoch 62/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4891 - accuracy: 0.7473 - val_loss: 0.5234 - val_accuracy: 0.7343\n",
      "Epoch 63/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4875 - accuracy: 0.7478 - val_loss: 0.5559 - val_accuracy: 0.7185\n",
      "Epoch 64/100\n",
      "1711/1711 [==============================] - 11s 6ms/step - loss: 0.4906 - accuracy: 0.7474 - val_loss: 0.4967 - val_accuracy: 0.7518\n",
      "Epoch 65/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4898 - accuracy: 0.7479 - val_loss: 0.5547 - val_accuracy: 0.7233\n",
      "Epoch 66/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4863 - accuracy: 0.7486 - val_loss: 0.5512 - val_accuracy: 0.7298\n",
      "Epoch 67/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4909 - accuracy: 0.7459 - val_loss: 0.4811 - val_accuracy: 0.7546\n",
      "Epoch 68/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4915 - accuracy: 0.7473 - val_loss: 0.5156 - val_accuracy: 0.7442\n",
      "Epoch 69/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4922 - accuracy: 0.7470 - val_loss: 0.5209 - val_accuracy: 0.7349\n",
      "Epoch 70/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4860 - accuracy: 0.7491 - val_loss: 0.4931 - val_accuracy: 0.7487\n",
      "Epoch 71/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4827 - accuracy: 0.7504 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
      "Epoch 72/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4907 - accuracy: 0.7473 - val_loss: 0.4838 - val_accuracy: 0.7531\n",
      "Epoch 73/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4854 - accuracy: 0.7483 - val_loss: 0.4928 - val_accuracy: 0.7525\n",
      "Epoch 74/100\n",
      "1711/1711 [==============================] - 13s 7ms/step - loss: 0.4852 - accuracy: 0.7484 - val_loss: 0.4983 - val_accuracy: 0.7482\n",
      "Epoch 75/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4829 - accuracy: 0.7511 - val_loss: 0.6937 - val_accuracy: 0.6937\n",
      "Epoch 76/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.4985 - accuracy: 0.7451 - val_loss: 0.5521 - val_accuracy: 0.7314\n",
      "Epoch 77/100\n",
      "1711/1711 [==============================] - 11s 7ms/step - loss: 0.5010 - accuracy: 0.7435 - val_loss: 0.5017 - val_accuracy: 0.7441\n",
      "Epoch 78/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4966 - accuracy: 0.7452 - val_loss: 0.4894 - val_accuracy: 0.7575\n",
      "Epoch 79/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4956 - accuracy: 0.7447 - val_loss: 0.5134 - val_accuracy: 0.7390\n",
      "Epoch 80/100\n",
      "1711/1711 [==============================] - 12s 7ms/step - loss: 0.4907 - accuracy: 0.7477 - val_loss: 0.5257 - val_accuracy: 0.7476\n",
      "Epoch 81/100\n",
      "1708/1711 [============================>.] - ETA: 0s - loss: 0.4889 - accuracy: 0.7481"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\nls0629\\DNN_original_transfer.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000012?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000012?line=1'>2</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m \u001b[39m256\u001b[39;49m, \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000012?line=2'>3</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000012?line=3'>4</a>\u001b[0m             validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/nls0629/DNN_original_transfer.ipynb#ch0000012?line=4'>5</a>\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback])\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1607\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1608\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1609\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1610\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1611\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1612\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1613\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1614\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1615\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1616\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1617\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1618\u001b[0m )\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2494\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2491\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2492\u001b[0m   (graph_function,\n\u001b[0;32m   2493\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2494\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2495\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \\\n",
    "    batch_size= 256, \\\n",
    "        epochs=100,\\\n",
    "            validation_data=(X_test, y_test), \\\n",
    "                callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 1024)              81920     \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 768)               787200    \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 768)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 512)               393728    \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,428,233\n",
      "Trainable params: 1,428,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLite 변환 후 Post Training Quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tensorflow import keras \n",
    "import tqdm\n",
    "model = keras.models.load_model('multiclass_best_model2.h5') # best 모델 로드 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFLite 모델 생성 및 양자화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmp6nxc01bz\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5716300"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"model0629/\") # tflite 모델 저장 경로 입력 \n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "tflite_model_file = tflite_models_dir/\"model6_0629.tflite\" # 모델 이름 작성 \n",
    "tflite_model_file.write_bytes(tflite_model) # 모델 크기 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동적 범위 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmph8u2v2j2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmph8u2v2j2\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1439960"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_quant_file = tflite_models_dir/\"model_ptq.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Float 16 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmph5jovb__\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmph5jovb__\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2861496"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16] # float 16 적용 \n",
    "\n",
    "tflite_fp16_model = converter.convert()\n",
    "tflite_model_fp16_file = tflite_models_dir/\"model6_0623_f16.tflite\" # float16 양자화 모델 이름 작성 \n",
    "tflite_model_fp16_file.write_bytes(tflite_fp16_model) # 모델 크기 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 정수 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpvlra3bdr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpvlra3bdr\\assets\n",
      "c:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1440768"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정수 전용 양자화 사용 \n",
    "# 입력 및 출력 텐서 양자화 \n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100): \n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"model6_intquant_0629.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체정수 양자화 / 입력, 출력값의 형태가 정수인지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "# 입력 및 출력 텐서가 정수 형식임을 확인 \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인터프리터 로드 , 텐서 할당 (동적 범위 양자화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
    "interpreter_quant.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인터프리터 로드, 텐서 할당 (float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "interpreter_fp16 = tf.lite.Interpreter(model_path=str(tflite_model_fp16_file))\n",
    "interpreter_fp16.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인터프리터 로드, 텐서 할당 (전체 정수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_int = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
    "interpreter_int.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i in tqdm.tqdm(range(len(X_test))):\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(X_test.iloc[i,:], axis=0).astype(np.uint8)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in tqdm.tqdm(range(len(prediction_digits))):\n",
    "    if prediction_digits[index] == y_test.iloc[index,:].argmax():\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187625/187625 [00:39<00:00, 4693.34it/s]\n",
      "100%|██████████| 187625/187625 [00:16<00:00, 11325.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7592271818787475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(interpreter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187625/187625 [00:43<00:00, 4286.50it/s]\n",
      "100%|██████████| 187625/187625 [00:16<00:00, 11488.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591525649566956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(interpreter_fp16)) # float16 양자화 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187625/187625 [50:55<00:00, 61.40it/s]\n",
      "100%|██████████| 187625/187625 [00:21<00:00, 8587.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09564823451032645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(interpreter_int)) # integer 양자화 tfllite 모델 정확도 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mixed')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77c9216bb41fe971aff2028ed5cd627687824622a49f5e0570ede26746645fdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
